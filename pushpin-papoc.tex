\documentclass[sigplan,10pt]{acmart}
\usepackage[utf8]{inputenc}
\usepackage{todonotes}

\copyrightyear{2019}
\acmYear{2019}
\setcopyright{acmlicensed}
\acmConference[PaPoC '20]{7th Workshop on Principles and Practice of Consistency for Distributed Data}{April 27, 2020}{Heraklion, Greece}
\acmBooktitle{7th Workshop on Principles and Practice of Consistency for Distributed Data (PaPoC '20), April 27, 2020, Heraklion, Greece}
\acmDOI{}
\acmPrice{}
\acmISBN{}

\hyphenation{Web-RTC}

\begin{document}
\title{PushPin: Towards Production-Quality  Peer-to-Peer Collaboration}

\author{Peter van Hardenberg}
\email{pvh@inkandswitch.com}
\affiliation{%
  \institution{Ink \& Switch, LLC}
  \city{San Francisco}
  \state{CA}
  \postcode{}
  \country{USA}
}

\author{Martin Kleppmann}
\email{mk428@cl.cam.ac.uk}
\orcid{0000-0001-7252-6958}
\affiliation{%
  \institution{University of Cambridge}
  \streetaddress{15 JJ Thomson Avenue}
  \city{Cambridge}
  \state{}
  \postcode{CB3 0FD}
  \country{United Kingdom}
}

\begin{abstract}
Fully peer-to-peer application software promises many benefits over cloud software, in particular, being able to function indefinitely without requiring servers.
Research on distributed consistency mechanisms such as CRDTs has laid the foundation for P2P data synchronisation and collaboration.
In this paper we report on our experience in taking these technologies beyond research prototypes, and working towards commercial-grade P2P collaboration software.
We identify approaches that work well in our experience, such as the functional reactive programming paradigm, and highlight areas in need of further research, such as the reliability of NAT traversal and usability challenges.
\end{abstract}

\begin{CCSXML}
<ccs2012>
    <concept>
        <concept_id>10003033.10003039.10003051.10003052</concept_id>
        <concept_desc>Networks~Peer-to-peer protocols</concept_desc>
        <concept_significance>500</concept_significance>
    </concept>
    <concept>
        <concept_id>10011007.10010940.10010971.10010972.10010540</concept_id>
        <concept_desc>Software and its engineering~Peer-to-peer architectures</concept_desc>
        <concept_significance>500</concept_significance>
    </concept>
    <concept>
        <concept_id>10003120.10003130.10003233</concept_id>
        <concept_desc>Human-centered computing~Collaborative and social computing systems and tools</concept_desc>
        <concept_significance>500</concept_significance>
    </concept>
    <concept>
        <concept_id>10011007.10010940.10010992.10010993.10010961</concept_id>
        <concept_desc>Software and its engineering~Synchronization</concept_desc>
        <concept_significance>300</concept_significance>
    </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Networks~Peer-to-peer protocols}
\ccsdesc[500]{Software and its engineering~Peer-to-peer architectures}
\ccsdesc[500]{Human-centered computing~Collaborative and social computing systems and tools}
\ccsdesc[300]{Software and its engineering~Synchronization}

\keywords{real-time collaboration, CRDTs, peer-to-peer protocols, distributed programming, usability}

\maketitle

\section{Introduction}

In the past, software used to run on one computer and store its data on the local disk.
Now, increasingly, we expect our software and data to be available on multiple devices, with synchronisation across devices belonging to the same user (e.g.\ laptop, smartphone, tablet), and also allowing real-time collaboration between multiple users.

The standard way of implementing such multi-user, multi-device software today is to rely on cloud services that store the authoritative copy of the users' data, and which can be accessed through thin clients such as web browsers and mobile apps.
However, reliance on the cloud comes with problems: services require ongoing maintenance by expensive 24/7 operations teams, and they cease to exist when the organisation backing them terminates their funding.
If a cloud service shuts down, users lose access to all data stored in that service, unless some migration path to an alternative service is provided.
Moreover, cloud-centric software often does not work well offline, and can be slow as the client waits for round-trips to the server in order to load or store data there.

Peer-to-peer application software promises to overcome these problems.
In principle, a P2P system should be able to function indefinitely, without depending on someone paying the server bills to keep a cloud service running.
Storing an authoritative copy of data on the users' devices enables offline work and stronger data ownership~\cite{LocalFirst}, and synchronising updates through a P2P network should allow the same kind of real-time collaboration that we know from cloud software.

While various research prototypes of P2P collaboration software have been developed, we are yet to see any mainstream applications using this approach.
Technologies such as Conflict-free Replicated Data Types (CRDTs)~\cite{Shapiro:2011un} and P2P data replication protocols (see Section~\ref{sec:networking}) provide a good foundation for this type of software, but there is still a big gap between these building blocks and the requirements of software with the features expected by users today.

For example, there are at least half a dozen CRDT algorithms for P2P collaboration on a plain text document~\cite{Kleppmann:2019iu}, and various P2P protocols that can replicate a static file.
However, there is little existing work on how to use these building blocks to implement a rich workspace containing potentially thousands of documents and files of various types, with facilities for organising, searching, and selectively sharing this content with other users.

The PushPin project is investigating if and how we can develop commercial-quality collaboration software with minimal reliance on servers.
Our goal is not to create new algorithms or protocols, but rather to evaluate existing technologies by developing an example P2P application with a mindset of industrial software development best practices and realistic user requirements.
We approach this project with broad interests in exploring programming models, P2P data distribution, reliability, and usability.

In summary, our findings are:
\begin{itemize}
    \item CRDTs provide a reliable, principled foundation for P2P collaboration.
    We found the details of conflict resolution semantics to be surprisingly unimportant, as conflicts seem to occur rarely in practice.
    \item The Functional Reactive Programming (FRP) approach is a good way of creating user interfaces on top of state managed by CRDTs (Section~\ref{sec:data-model-ui}).
    \item P2P protocols are poorly supported by many network routers (Section~\ref{sec:networking}).
    Consequently, the use of servers to forward network traffic is sometimes unavoidable.
    \item The performance of CRDTs and P2P replication implementations becomes problematic as the amount of data grows. The storage and processing overheads of current implementations are substantial.
    \item Significant open problems remain, including around authentication and access control, indexing and search, schema evolution and compatibility, privacy, and the usability of systems where some devices are in sync while others are not.
\end{itemize}

% The prize for delivering a truly peer-to-peer application development system is great.
% centralised cloud-based software has created the expectation of universal access to both canonical versions of software and to users' data from any internet-connected computer at any moment, with full collaborative functionality built in.

%To this end, we must reconsider our relationship with vast centralised databases and explore new methodologies for building software.

% document CRDTs
% functional reactive programming
% browser rendering
% "document oriented programming"

\section{Design Principles}\label{sec:principles}

Before going into the details of the implementation of PushPin we outline the principles we applied to its design and development.

\subsection{Local-first software}

While we want users' data to be accessible on multiple devices, the authoritative copies of this data should reside on the users' local computers, not in the cloud.
If servers are used, these replicas should be considered secondary copies that exist only to facilitate data synchronisation and backup, but they should not be considered authoritative.
In previous work we have coined the term \emph{local-first software} to describe software that adheres to this principle~\cite{LocalFirst}.

With a local-first approach, the software continues working fully if the user's computer is disconnected from the Internet: cross-device synchronisation happens in the background when a network connection is available.
Even if all servers are shut down, the copy of the data on the local disk remains fully functional and under the user's control.
The user can manage this data like any other local files, e.g.\ copying it, backing it up, or converting it into another format.

\subsection{Minimal dependence on servers}

We want the software to continue working indefinitely, without being vulnerable to outages if the organisation running some piece of infrastructure goes out of business.
Thus, in addition to local data storage on each device, the cross-device data synchronisation mechanism should also depend on servers to the least degree possible.

In some environments it is possible to operate entirely without servers, while in other cases a small amount of centralised infrastructure seems to be inevitable with current technologies.
However, if servers are used, we want them to be as simple and fungible as possible, so that one failed server can easily be replaced by another.

\subsection{Conflict-free data synchronisation}

The combination of using local on-device storage, support for offline editing, and synchronisation without servers implies that our application is \emph{intrinsically distributed}.
Each device serves as a replica, and it would not make sense to enforce any kind of single system image semantics across replicas, since that would imply that a device must wait for synchronous coordination with other devices whenever any data is changed.
We cannot rely on consensus algorithms, which must wait for communication with a quorum of replicas.

Rather, we have to accept that each device has its own local view onto the shared data, and that those views may diverge as users update their data.
As devices exchange updates, they converge again by merging their states.
We do this using conflict-free replicated data types (CRDTs)~\cite{Shapiro:2011un}.

\subsection{Mainstream, as far as possible}

In order to explore the \emph{user experience} implications of a peer-to-peer architecture, we wanted to develop not just a rough research prototype, but polished end-user software that is on par with commercial applications available today, with a thoughtful graphical and interaction design.
We also wanted to explore the \emph{developer experience} of peer-to-peer software, to understand how writing software with this architecture could become accessible to mainstream software engineers.
Thus, we wanted to base our work on mainstream languages and platforms as far as possible.

\begin{figure*}
    \centering
    \includegraphics[width=0.7\textwidth]{pushpin.jpg}
    \caption{Screenshot of PushPin. The main user interface consists of cards of various types (text, image, PDF, \dots) that can be freely arranged on a 2D ``board''. Boards can be nested within other boards. The toolbar at the top provides navigation between boards and sharing settings.}
    \label{fig:pushpin}
\end{figure*}

\section{PushPin: A Collaborative Corkboard}\label{sec:pushpin}

The PushPin software~\cite{PushPinSource}, shown in Figure~\ref{fig:pushpin}, allows users to collect media of various types (including text, web pages, images, and PDF files), to archive and organise it.
Media files are visually represented as \emph{cards} on an infinite two-dimensional \emph{board}, where they can be resized and positioned arbitrarily.
One board may be nested within another board, enabling hierarchical organisation and navigation.
This board metaphor is known from other note-taking software such as Miro~\cite{Miro} and Milanote~\cite{Milanote}.

We chose this application because it fits well with the principles articulated in Section~\ref{sec:principles}: the data in this software belongs to the user, and there are essentially no restrictions as to what the user may do with their data.
Unlike some systems (e.g.\ banking or payment systems, auction websites, ride-sharing, or games), in this application there is no need to enforce any global rules or consensus across users, and there is no need for an authority to decide what actions are allowed.
The only restrictions are access permissions (i.e.\ defining which user may view or modify which pieces of data), but we assume that a user with permission to edit some piece of data may modify it in any way.


\subsection{Building desktop software with Electron}

In recent years there has been considerable innovation in web application technologies, including in web browsers (new features of HTML and CSS), languages (e.g.\ TypeScript), user interface libraries (especially React~\cite{React}), and JavaScript modules for a wide variety of tasks (e.g.\ PDF rendering~\cite{PDFjs}).
In order to take advantage of this lively ecosystem, we decided to implement PushPin using web technologies.

However, web applications running in a browser tab have constraints that make them unsuitable for local-first/P2P use. By default, browsers do not reliably store any data. Web developers can modify their applications to incrementally add support for usage offline or to store data locally, but even in the best case where a developer implements their application using APIs like localStorage and IndexedDB or implements the elements of a Progressive Web App, the application still runs in a browser tab identified by a web URL. Users have no way of predicting whether their data or the application will be available when they need it. The browser can expire the application's data from its cache without notification, and often it requires manual steps to enable offline support. For example, the Google Docs web application supports offline usage, but it involves installing a special browser extension and only preserves documents the user has previously opened. Anecdotally, it appears to be common for users to only realise the data they thought they'd prepared for offline usage is unavailable once it is too late. For security reasons, mainstream web browsers also only support client-server requests (primarily via HTTP and subject to same-origin policy~\cite{SameOrigin}), with no support for implementing peer-to-peer protocols using arbitrary TCP or UDP networking.

We avoid these limitations by building on Electron~\cite{Electron}. Electron packages a JavaScript web application and a dedicated Chromium-based browser run-time, enabling cross-platform support for Mac OS, Windows, and Linux (not to mention reuse of organisational web development skills). An Electron application is a better fit for local-first development than a web app. A user can trust that the software they install will be available when they need it, because they have taken a conscious action to install it. That said, developers must still choose to prioritise supporting local storage of user data. Although many Electron applications are thin wrappers around the existing web application, some, like Microsoft's Visual Studio Code, are robust local-first applications. Also, Electron makes Node.js APIs available to application code, which enables full access to the local filesystem, and socket APIs allowing arbitrary TCP and UDP networking.

\section{Data Model and User Interfaces}\label{sec:data-model-ui}

In the early days of the web, browsers traversed static HTML. As time went on, web applications became increasingly powerful and a separation of responsibilities between server-side and client-side code emerged. Conceptually, a Single Page App (SPA) is a static program which runs in the client's browser and makes requests to server-side APIs for the data it requires to respond to user input. (Practically speaking it is common to blur these distinctions, such as by doing some server-side rendering of initial state.) Managing the state of the client-side application in an ad-hoc way can be difficult, managing the currently rendered state of the browser, overlapping web requests, user input, and so on. 

Functional Reactive Programming (FRP) reduces the complexity of the problem by creating a simple, reliable relationship between program state and visualisation. Application state is rendered deterministically to the browser's DOM, and interactions with the application update that underlying state triggering new renders. Performance is improved by incremental update algorithms that efficiently reconcile the application state with current DOM representation.

Although FRP reduces the complexity of mapping state to display, it does not address communication with back-end APIs. The benefit of FRP's simple programming model is eroded by side-effects created by asynchronous calls to backing services that can manipulate state. Although the GraphQL effort by Facebook provides a more structured communication channel between front-end and back-end, the process of managing local and remote state is still quite complex.

\subsection{Document FRP (DFRP)}

We call our approach to reducing this complexity Document FRP (DFRP). We couple the state of an FRP program to an Automerge CRDT~\cite{Automerge,Automerge:2018}, and then distribute that state with other peers (including both clients and servers) using peer-to-peer networking. The DFRP model allows developers to write once-complex local-first software without concern for communication with APIs, but rather users a shared state as a communication channel. This state can be updated by any involved party, online or offline, and Automerge takes care of reconciling the changes. During network partitions, changes are automatically accumulated on individual peers until communication is restored. The result is that a developer can simply write client-side code and the system will take care of the rest.

Consider a simplified PushPin board. The cards on the board are a list of items with positions and dimension and contents. When a user creates a new card, it is inserted into the list, and the instrumenting of the CRDT data structure detects that change and records it as an automerge operation for distribution to other users. If another user moves a card, only the x and y fields are changed and this too becomes a simple change to merge with other changes.

\subsection{Example Document: Board}
\begin{verbatim}
{
  title: "Inspiration",
  authors: [
    hypermerge:<hash>?contentType=contact,     
    hypermerge:<hash>?contentType=contact,
    hypermerge:<hash>?contentType=contact
  ],
  cards: [
    { x: 12, y: 84, w: 77, h: 184, url: "hypermerge:/<hash>?contentType=text"}
    { x: 12, y: 84, w: 77, h: 184, url: "hypermerge:/<hash2>?contentType=image"}
    { x: 12, y: 84, w: 70, h: 334, url:     "hypermerge:/<hash3>?contentType=todo-list"}
  ]
}
\end{verbatim}

\subsection{Example Document: Contact}
\begin{verbatim}
{
  name: "Peter van Hardenberg"
  avatar: "hypermerge:<hash>?contentType=image",
  devices: [
    "hypermerge:<hash>?contentType=device",
    "hypermerge:<hash>?contentType=device"
  ]
}

\end{verbatim}

\fig{FIGURE HERE SHOWING SIMPLE BOARD CHANGES}

The logical changes -- creation of cards and so on -- are translated into automerge data that is then propagated out through the render function to the user. The origin of these changes is irrelevant, because the result is consistent. A TODO item created on a remote computer follows the same route to the display as one created locally, and automerge guarantees all communicating nodes will produce the same document.

This is the key. Automerge guarantees consistency of data across communicating systems, and FRP guarantees consistency of display.

% challenges: getting into weird states, write permissions

\subsection{Ephemeral state, local-only & shared}

Our earliest experiments put all data into the CRDT. This quickly proved to be problematic, as many useful data like unsubmitted text in HTML textboxes or cursor positions are ill-suited to universal consensus. Also, some data, like cursor position or timers for tracking animations, can completely swamp the CRDT with low-value information.

The first natural extension then was to redefine the function describing the application state to include a second ephemeral local-only state that is neither persisted nor distributed. Some of this kind of ephemeral or high-velocity data is, however, useful to share with online peers.

It can be helpful to see whether other users are viewing the same document as you, or what text or items they have selected. It might be interesting to see another user's current position in a podcast or video, or a hint that shows they're currently typing into a chat textbox they've not yet submitted.

For this data PushPin uses a special messaging channel adjacent to the CRDT that ties arbitrary messages to a device and user context. The current implementation is rudimentary. The ephemeral data is not associated with a particular CRDT state, and is distributed only over live connections so will not function as expected in complex network topologies or at large scale. Still, it has allowed us to add important liveliness to the user experience of PushPin. Particularly in distributed applications it is important to communicate the feeling of presence when other users are online or collaborating, because unlike in a centralized system there are many ways to be both online or off.

\subsection{Multiple Documents}
In actual fact, the contents of a card on a PushPin board are not stored directly in the document for the board, but are each, themselves a PushPin URL. 

A PushPin URL defines two elements: a document URL to render, and the name of a renderer to use to view it. For example, a card URL might look like:

% i made up this coding, and assume it is incorrect
\begin{code}
hypermerge:/FJ2NEbKxNM69cdsGtqojSFSJm9JjtNjdASHxAZTywjee?pushpinContentType=board
\end{code}

This URL is sufficient information to recursively render a child document with its own context, with its own FRP functions, each of which could contain their own sub-documents and renderers.

Decomposing the view into a graph of documents allows for significant simplification of the overall FRP update functions and makes them reusable. The same code that renders a text card, or a user avatar can render that document in some other context. Indeed, it is possible to create generic, reusable renderers that visualise arbitrary documents, or specialised renderers that render the same document in new contexts. A simple example of this is the PushPin title-bar. The current document is re-rendered by a second FRP function that only renders the title field and list of authors. 


\subsection{Sharing, permissions}

Every document within PushPin is uniquely identified by a URL. That URL can be reused throughout the application, or shared with another user to begin collaboration. (For example, PushPin supports copying a URL from the application and pasting it into another client to share data.) The URL is a handy but imperfect tool for scoping a collaboration. Because each URL is a stable name associated with a single CRDT it can be shared individually. Further, a recipient can recurse from that document through others to download all the other related documents for a collaboration without learning of the existence of any other data. 

Unfortunately, the stability of these URLs is somewhat problematically strong. The URLs function as a sort of security capability, and once a client has seen the URL, there is no real mechanism in the current system to revoke or rotate it. Further, while we believe CRDTs are an exciting area to explore new collaboration models \cite{Pixelpusher} we have not pursued this effort in PushPin. We have often described our approach in PushPin as "radical mandatory collaboration". Once a document has been shared, a client will always accept all updates to it from all users with the URL anywhere forever. This is, to be clear, not a good design, but rather a deliberate absence of design. 

\subsection{Users}

Opaque cryptographic hashes are difficult to recognize and remember, subject to transcription errors, and don't communicate origin or authorship in the way that traditional web URLs can. Within PushPin, we don't have a centralized account system, but we did want to have a way for users to identify themselves to other participants and share content with those they've met before. We also felt it was important to include in-app document sharing that relied as little as possible on copying and pasting links outside the application.

First, in PushPin we model users as regular documents. Users have a name and a contact photo. This document also stores information about what documents users are sharing as an "outbox". An outbox is an inbox, in reverse. It is a list of documents you'd like other people to be able to access, and the data structure is simple. The "shares" field on a user document is a map from user profile document IDs to a list of URLs being shared. We chose this structure to allow users to post shares for people whose identities they have but who they have not yet connected with. Given Bob's contact information, Alice can post a share for him, then go offline. As long as that data is hosted by some other node in the graph (either a storage peer or a collaborator), when Bob requests Alice's profile document, he can download the relevant data.

Of course, the first and most obvious problem is that these shares should not be plain-text. We solve this problem by obfuscating shares inside a sealed-box encryption payload based on the public key shared by the recipient. This public key is important. If it were to be replaced by another user, that person would hijack access to all documents being sent to the original recipient.

This problem led us to our first experiments in implementing something like "merge permissions" in PushPin. Briefly, this special key is protected by a designation that causes all other authors' writes to the key to be ignored. This limited nod to the notion that users should make informed decisions about which changes they accept was forced by concern for the security of our beta testing group and does not yet reflect a fully considered design.

\subsection{Devices}

PushPin is designed to support not just collaboration between people, but also collaboration across a users' own devices \footnote{Notably, PushPin does not have mobile support and many elements of its design are unavailable on most mainstream mobile devices today.}. A user document includes a list of devices they are associated with, and users are considered online if any of those devices are reachable. Availability of a users' own devices is also important. A user with no other online devices is making changes without a backup. If another of their devices is online, their work can be synchronised there and become more durable. It can be important to a user to understand their relative state to a variety of users. If PushPin has sent a fresh copy of a document to an offline user just a moment ago, that's meaningfully different than if the user does not appear to have used the application in weeks. 

\subsection{Notes on CRDT Performance}

Automerge's performance has proven adequate for our purposes, but we believe that "next-frame" performance is essential for high-quality user experience. This implies that the application's front-end should never be blocked by performing background tasks like encryption, CRDT computation, or other non-essential work. Many web applications use a technique called "optimistic UI updates" to allow for local changes to be represented in the front-end before they are confirmed elsewhere. Pushpin implements this holistically across all documents in the application by separating the front-end, a mechanically simple interface to fully assembled CRDT documents, from the back-end, where CRDTs are compiled out of the streams of operations that describe them. When a change is made in the front-end, it is always applied there immediately and also submitted to the back-end, which runs in another process. The back-end applies the change, integrating it with any other waiting changes, and forward the resulting finalised document back to the front-end.

This technique, which we have not seen realised in other systems, allows us to reliably deliver a 60 frames-per-second user experience even when there are many CRDT operations ongoing in a busy collaboration.

\subsection{Cloud Peers for Storage, Enhanced Connectivity & Other Uses}

As discussed elsewhere, one of our key goals with this project was to make cloud infrastructure optional rather than mandatory, but we recognize that servers have an important role to play in any resilient system. For PushPin, we implemented pushpin-peer, a sibling project that runs the same document sharing stack but as a simple Unix daemon without any visual front-end. The main role for pushpin-peer is data presence. A user can store a URL with pushpin-peer and the tool will download all subsequent versions of that document, spider out through any links within that document (and so on from those), and of course, it can serve up that data to other clients requesting it. We feel this is an important distinction from the notion of "pinning" found in some other systems such as IPFS. In general, PushPin is a creative tool oriented towards storing data created locally by the user or by one of their collaborators. The default should be to preserve everything! In contrast, IPFS is oriented towards generic binary object storage, and so does not assume that interacting with an object would imply wanting to retain it indefinitely.

One of the goals for pushpin-peer was that the UI had to be self-hosted, which is to say that all the interactions with it should occur within PushPin and not in some other web administration tool. When pushpin-peer starts up, it prints out a URL that users can load from their PushPin. Users interact with their cloud peer from within PushPin by making edits to PushPin's adminstration document. The pushpin-peer daemon monitors that document for changes and takes actions based on what it finds. This approach was first pioneered in our work on pixelpusher, and has returned with greater sophistication here. Most importantly, pushpin-peer uses similar techniques to the user document sharing approach described above to allow clients to write private URLs to a document other peers may read without disclosing their contents.

\section{Peer-to-peer Networking for Collaboration}\label{sec:networking}

Every networked application relies on three core facilities provided by the networking stack: discovering the network address to connect to, establishing a connection, and securing the confidentiality and integrity of the data transfer.

In a traditional web application, discovery is provided by DNS, connection by TCP, and security by SSL/TLS.
However, these technologies are not a good fit with our goal of minimising centralised infrastructure and ongoing cost:
\begin{itemize}
    \item DNS requires paying ongoing registration fees for domain names, and it requires running DNS servers.
    \item TCP requires the server to have a publicly routeable IP address; it cannot connect directly to most end-user devices as they are behind NAT (see Section~\ref{sec:nat-traversal}).
    \item SSL/TLS certificates are tied to domain names, which incur registration fees.
\end{itemize}

The peer-to-peer technologies we explored in PushPin attempt to overcome the need for centralised infrastructure.

\subsection{Existing Peer-to-Peer Technologies}

We considered several P2P networking stacks for PushPin:
\begin{description}
\item[WebRTC] is a peer-to-peer protocol built into modern web browsers.
It is primarily designed for audio and video calls, but it can also carry application data.
WebRTC does not provide a peer discovery mechanism; typically, applications rely on a server to help peers discover each others' IP addresses (this process is called \emph{signaling}).
\item[BitTorrent] is widely used for file sharing.
It provides a distributed hash table (DHT) for peer discovery, and uses the uTP protocol to establish connections between peers.
However, it is designed for static files, and is not suitable for data that is constantly changing, like in collaboration software.
\item[IPFS] aims to provide decentralised storage through a networking stack called \emph{libp2p}.
Like BitTorrent, it is mostly focused on replicating static files; it provides limited support for changing data through its IPNS and PubSub modules, but these features are immature at the time of writing.
\item[Dat] \cite{HowDatWorks,Ogden:2018ur} is a peer-to-peer data sharing platform.
For peer discovery it uses a centralised DNS service hosted by a nonprofit foundation (a distributed hash table is under development), and it uses BitTorrent's uTP protocol to establish connections.
\end{description}

PushPin builds upon the \emph{hypercore} protocol and implementation from the Dat project~\cite{HowDatWorks}, since its focus on replicating mutable data makes it the best fit for our needs.

A hypercore is an append-only log that is authenticated with a public key; only the owner of the corresponding private key can modify the log, but many peers can store replicas of the log.
We map each PushPin document to a set of hypercores, with one hypercore per device that has edited the document.

\subsection{Peer Discovery}

The Dat protocol allows the replicas of a hypercore to be discovered based on a hash of its public key~\cite{HowDatWorks}.
We encode this public key in the form of a URL; thus, the URL is a stable identifier for the document, even as its content changes.
Knowledge of the URL allows a peer to obtain a copy of the document, via the peer discovery mechanism.
We allow one document to reference another by including the referenced document's URL in another document.

When peers are on the same LAN (wired or wireless network), they attempt to discover one another using mDNS, a variation on DNS that broadcasts DNS-like service advertisements or discovery requests to a well known multicast IP address.
If successful, the peers can connect directly via TCP and begin exchanging data.
This mode of discovery is appealing since it depends only on the local network: communication between peers does not flow via the Internet, and it does not depend on any centralised infrastructure.

When peers are not on the same LAN, the Dat protocol uses a centralised DNS server for peer discovery.
This approach is not fully peer-to-peer, but at present this seems to be a necessary compromise to make.
Since the DNS server only provides peer discovery, and does not handle any data transfer traffic, it is quite cheap to run.

\subsection{NAT Traversal}\label{sec:nat-traversal}

Due to a shortage of IPv4 addresses, most personal computing devices do not have a globally reachable IP address, but rather a local address in a reserved space (e.g.\ 192.168.x.x or 10.x.x.x).
When such a device wishes to establish a connection to another, the local router records the destination of outbound traffic and routes responses back to the originating local client.
This process is called Network Address Translation (NAT).

A device behind NAT can make outbound connections, but it cannot receive inbound TCP connections from outside of the NAT.
An exception: in home environments, where the user has control over their own router, the UPnP standard allows devices to reserve particular ports on the router's public IP address as the destination for inbound connections.
However, mobile devices often use networks with NAT on which UPnP is not available, such as a coffee shop WiFi, a corporate office network, or a cellular data network.

In these cases, the most viable solution is known as ``hole punching'' or NAT traversal \cite{RFC5389}.
This process requires the temporary intervention of a third host to introduce the two peers, and both peers sending UDP packets to each other, allowing a connection to be established.
NAT traversal is performed by BitTorrent's uTP protocol, and by the STUN protocol in WebRTC \cite{RFC5389}.

However, there are situations in which neither the LAN discovery approach nor NAT traversal works.
For example, some coffee-shop WiFi and some corporate networks are set up in a ``guest network'' mode, which prevents all local connections between devices on the network (intended as a security measure to prevent inadvertent sharing of data with other users on a public network).
Without local traffic, we attempt to fall back on NAT traversal; however, this approach also fails, since many routers in their default configuration refuse to create NAT traversing routes that originate and terminate within the same network.

In this case, establishing a direct connection between the peers seems to be impossible, and the only remaining option is to use a server to proxy the communication between the peers, e.g.\ using the TURN protocol~\cite{RFC5766}.
In the case of PushPin, users can either run their own publicly addressable network hosts or take advantage of a TURN server provided by the community.

\subsection{Storage Peers}

A limitation of any peer-to-peer system is that two peers can only communicate while they are both online.
However, mobile devices are often offline, making it difficult to find an opportunity to synchronise.
For example, if your colleague has shared the URL of a PushPin board with you, it would be annoying if you could not access that board because the only copy of the board resides on your colleague's laptop, and that laptop's lid is currently closed.

We can overcome this limitation by introducing \emph{storage peers}, which replicate all the data belonging to a particular user or set of users.
A storage peer runs the same replication protocol as any other peer; the difference is only that it is always online, allowing other devices to sync with the storage peer at any time.
Storage peers also provide a form of backup.

Unlike a traditional server, a storage peer can be reached through NAT traversal, so it does not need a public IP address: for example, it could be a device on the user's home internet connection.
Since it only stores the data for a small number of users, it does not need to be a powerful machine.
We have experimented with using a Raspberry Pi as storage peer, writing data to an SD card.

\subsection{Data Confidentiality and Integrity}

Some peer-to-peer systems, such as BitTorrent and IPFS, use a content-addressable storage approach to data integrity: every file is identified by the hash of its contents, and the recipient can check the integrity of the file by comparing its actual hash to the expected hash.
(In fact, BitTorrent uses Merkle trees \cite{Merkle:1987} to allow efficient incremental validation of data during its download.)
However, this approach is not suitable for collaboration software, where the the hash would frequently change as data is modified.
Instead, Dat relies on digital signatures to ensure that nobody can make undetected alterations to the data without knowing the private key.

The Dat protocol encrypts the communication between peers, using the URL of the document as a shared secret to establish the encryption key~\cite{HowDatWorks}.
Thus, the URL acts as a bearer token (or capability) that grants read access to the document to anyone who knows it.
We are interested in stronger access control and end-to-end encryption protocols for collaboration software~\cite{Kleppmann:2018tk}, but we have left this issue out of scope in the PushPin project.

The peer discovery protocol uses hashes of URLs, not the URLs themselves, so that anyone observing the peer discovery traffic (such as the DNS server, or other devices on the local network when using mDNS) does not gain the ability to read the document.

\subsection{Scalability of Peer Discovery}

% (It should be noted that in practice today, the BitTorrent DHT has proven itself operationally resilient but other implementations such as IPFS have struggled to remain useful during flooding attacks.)

On a local network, a Dat peer broadcasts all the hashes of URLs for data it holds, and all the hashes it requests.
This approach is suitable when the number of URLs is small, but it breaks down as collections expand.
Since PushPin uses a separate URL for each card, a user quickly accumulates many hundreds or thousands of document URLs.
In our testing we found that we could fairly reliably crash the consumer-grade WiFi routers found in short-term rentals with half a dozen researchers sharing their collections.

% TODO: diagram of append-only logs, discovery keys, maybe broadcasting?

The Secure Scuttlebutt~\cite{Tarr:2019ba} project avoids this problem by placing all of a user's activity into a single log, which it then merges with all of that user's peers and their peers out for several degrees of social connection. This trades one problem for another: by merging all of a user's data (and their peers' data) into one feed, there is no way to selectively synchronise that user. A peer either downloads all, or none.

Fortunately, we have observed that users tend to collaborate on more than one document with the same collaborator.
Thus, when searching for peers that have a copy of a new document, it is likely that this document of interest can be found in the repository of a peer you are already connected to.
We can significantly reduce the amount of discovery network traffic by first querying existing peers, and only performing a global DHT lookup if this fails.
Perhaps these peers could also forward queries on our behalf, recreating a DHT-like network.
This is an area for future work.

\subsection{Metadata Privacy}

A downside of peer-to-peer protocols is that the peer discovery mechanisms leak information about users to other nodes on the network.
Although the content of documents is only available to peers who know their URLs, the discovery keys (hashes of URLs) are widely broadcast, allowing a user's device to be identified by the pattern of discovery keys it shares.
With this information, an attacker can monitor a user's IP address over time, and thus track their approximate physical location.

A number of defences could reduce this tracking potential (e.g.\ automatic rotation of discovery keys, or some form of interactive proof exchange through a third party prior to exposing IP addresses), but this remains an area of active concern and research.

\section{Lessons from Implementing PushPin}\label{sec:lessons}

Our goal in building PushPin was to explore whether it was possible to apply recent developments in CRDTs and peer-to-peer networking with modern web development technologies to produce an application with several properties.

Those properties are:
 - long-now reliability, by not relying on external network services
 - real-time collaboration throughout the software
 - consistent performance with low latency
 - a high degree of usability for a general audience 

Because of the first and second goals Peer-to-peer systems have a number of unique challenges versus centralised systems, including:

\begin{itemize}
	\item no single source of truth, no single authority

	Without a centralised server hosting an authoritative copy, every copy of the data becomes, in some sense, authoritative. This implies that we must have some kind of robust merging strategy at the core of our design.
	
	\item devices get out of sync

    Because we insist that each device is always able to make progress without communication with other nodes, it is vitally important to both do our best to synchronise our various devices, but also to communicate synchronisation state. What were the last changes received from our laptop? Did the changes we made locally get uploaded to a server before the network connection was lost?  

    \item connectivity is non-boolean

    With a centralised system a user is either offline or online. The central node routes all data. With a peer-to-peer system is is entirely possible that you might be connected with another user around the world but due to the complexities of computer networking, disconnected from a user in the same room. (Perhaps their wifi connection is offline.) 

    \item changes can come from anywhere at any time

    Without the centralised system approving or rejecting changes against a monotonically incrementing API version, it's possible that other clients are running older, newer, or just different versions of the program. How do we robustly manage change over time?
    
    \item different devices might be running different versions of the software, and they need to interoperate cleanly
\end{itemize}

It is a sad truth that peer-to-peer software has earned a rather poor reputation not just for reliability but also as a vector of illicit activity. Because of this, router vendors and network administrators both collude to restrict peer-to-peer communications and simply fail to support them.

what works, what's not working so well?

\begin{itemize}
    \item FRP render loop works great -- taking a functional transform of a document state to application view means never worrying about where the update came from or how to render it
	\item storing \& distributing append-only logs is very simple and robust
    \item peer-to-peer networking is highly problematic
    \begin{itemize}
	    \item webrtc (not very good, requires centralized assets)
		\item DHTs (reliability, privacy)
		\item centralized services (fragility)
		\item router configuration issues
	\end{itemize}
	\item much performance work has been done
	\begin{itemize}
	    \item architect to separate render \& computation of CRDT operations
	\end{itemize}
	\item conflict resolution surprisingly unproblematic
	\item merge \& collaboration UX is largely unexplored (could show a pixelpusher slide \& briefly explain problems)
	\item what kind of identity, privacy, sharing features are important / feasible here?
	\item html is a pretty rough application development platform
	\item no real mobile support
	\begin{itemize}
	    \item what's the cross-platform story?
	\end{itemize}
\end{itemize}

By creating documents out of trustworthy append-only logs with stable names, we enable links and stably-named collaborative documents. A variety of state-of-the-art networking strategies overcomes the limitations of commonly available NAT routers in the field. Unfortunately, these techniques are not reliable enough to eliminate all traffic proxy requirements, and so we employ optional, but helpful network-persistent peers which act as relay points and data caches to improve reliability. (Importantly, they are not a central resource but can be run by any motivated network participant.) Last, we discuss some of our early work in improving discovery strategies for scalability without sacrificing specificity and some of the problems with current distributed hash table implementations today.

\section{Conclusions}

Let us begin by reiterating our goals:
\begin{itemize}
    \item To deliver 
\end{itemize}

CRDT / Application Model
\begin{itemize}
	\item We find modelling collaboration sessions as Automerge CRDTs is effective
	\item Tying CRDTs to user interfaces via FRP reduces complexity by funneling local and remote changes through a consistent process and eliminates ad-hoc calls to APIs
	\item Our DFRP approach makes all collaboration real-time by default
	\item We can build up complex application states by rendering several related documents (directories, text notes, user profiles) each with their own context-specific rendering function for a particular CRDT
	\item It is important to have stable names referring to data that evolves over time, content hashing is not effective
	\item Automerge's performance is adequate for building real user applications
\end{itemize}

Networking
\begin{itemize}
    \item Peer-to-peer networking has three stages: content discovery, connection establishment, and synchronisation
    \item The most promising techniques for discovery are based on the distributed hash tables pioneered by BitTorrent, supplemented by mDNS locally
    \item Connection establishment is complicated by the widespread assumption of client-server architectures and widespread NAT routing
    \item Connectivity in public environments like cafes and corporate offices can be particularly challenging 
    \item The state of the art for NAT traversal in public environment is "hole punching", built on top of UDP. PushPin uses UTP, also from BitTorrent
    \item 
    \item Autonomic (self-validating data) is an valuable concept in a low-trust environment
	\item 
\end{itemize}

Future work
\begin{itemize}
    \item Migrating data between versions and preventing invalid document states remains a concerning problem
    \item Establishing direct peer-to-peer connectivity is problematic in several important environments
    \item Distributed Hash Table side channels are a concerning source of privacy leaks
    \item The PushPin implementation assumes all writes are accepted, an obvious area for additional research & development
    \item New and old networking stacks have promise to improve connectivity, including BLE, WiFiDirect, and ultrasonic modems
    \item PushPin currently leaves almost all data un-encrypted, requiring trust in any peer that stores your data
    \item The need for rotation of public keys for data is a known and unexplored issue
    \item Some form of efficient document query or index documents are needed -- displaying a list of titles for documents requires fully loading all searchable documents
\end{itemize}

\begin{acks}
Thank you to Roshan Choxi, Ignatius Gilfedder, Mark McGranaghan, Jeff Peterson, and Matt Tognetti, who contributed to the development of PushPin.
The project was produced under the auspices of the Ink \& Switch research lab (\url{https://www.inkandswitch.com/}).
Martin Kleppmann is supported by a Leverhulme Trust Early Career Fellowship and by the Isaac Newton Trust.
\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}{}
\end{document}
